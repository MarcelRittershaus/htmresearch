{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXP 4-NoisySinusoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from nupic.encoders import ScalarEncoder\n",
    "from nupic.bindings.algorithms import TemporalMemory as TM\n",
    "from nupic.bindings.algorithms import SpatialPooler as SP\n",
    "from htmresearch.support.neural_correlations_utils import *\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputSize = 109\n",
    "maxItems = 15000\n",
    "totalTS = maxItems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tm = TM(columnDimensions = (2048,),\n",
    "        cellsPerColumn=8, # originally this value is 32\n",
    "        initialPermanence=0.21,\n",
    "        connectedPermanence=0.3,\n",
    "        minThreshold=15,\n",
    "        maxNewSynapseCount=40,\n",
    "        permanenceIncrement=0.1,\n",
    "        permanenceDecrement=0.1,\n",
    "        activationThreshold=15,\n",
    "        predictedSegmentDecrement=0.01\n",
    "       )\n",
    "\n",
    "sparsity = 0.02\n",
    "sparseCols = int(tm.numberOfColumns() * sparsity)\n",
    "\n",
    "sp = SP(inputDimensions=(inputSize,),\n",
    "        columnDimensions=(2048,),\n",
    "        potentialRadius = int(0.5*inputSize),\n",
    "        numActiveColumnsPerInhArea = sparseCols,\n",
    "        globalInhibition = True,\n",
    "        synPermActiveInc = 0.0001,\n",
    "        synPermInactiveDec = 0.0005,\n",
    "        synPermConnected = 0.5,\n",
    "        maxBoost = 1.0,\n",
    "        spVerbosity = 1\n",
    "       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random data\n",
    "noiseLevel = 0.25\n",
    "x = np.linspace(-100, 100, maxItems)\n",
    "y = np.sin(x)\n",
    "noise = np.random.normal(0, noiseLevel, maxItems)\n",
    "\n",
    "noisY = np.sin(x) + noise\n",
    "plt.plot(x, noisY)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.savefig(\"rawData\")\n",
    "plt.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 items processed\n",
      "2000 items processed\n",
      "3000 items processed\n",
      "4000 items processed\n",
      "5000 items processed\n",
      "6000 items processed\n",
      "7000 items processed\n",
      "8000 items processed\n",
      "9000 items processed\n",
      "10000 items processed\n",
      "11000 items processed\n",
      "12000 items processed\n",
      "13000 items processed\n",
      "14000 items processed\n",
      "*** All items encoded! ***\n"
     ]
    }
   ],
   "source": [
    "numTrainingItems = 7500\n",
    "trainSet = []\n",
    "nonTrainSet = []\n",
    "\n",
    "se = ScalarEncoder(n=109, w=29, minval=min(noisY), maxval=max(noisY), clipInput=True)\n",
    "\n",
    "for i in range(maxItems):\n",
    "    if i > 0 and i % 1000 == 0:\n",
    "        print str(i) + \" items processed\"\n",
    "    if i < numTrainingItems:\n",
    "        trainSet.append(se.encode(noisY[i]))\n",
    "    else:\n",
    "        nonTrainSet.append(se.encode(noisY[i]))\n",
    "print \"*** All items encoded! ***\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Spatial Pooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 0\n",
      "Training epoch: 1\n",
      "Training epoch: 2\n",
      "Training epoch: 3\n",
      "Training epoch: 4\n",
      "500 items processed\n",
      "1000 items processed\n",
      "1500 items processed\n",
      "2000 items processed\n",
      "2500 items processed\n",
      "3000 items processed\n",
      "3500 items processed\n",
      "4000 items processed\n",
      "4500 items processed\n",
      "5000 items processed\n",
      "5500 items processed\n",
      "6000 items processed\n",
      "6500 items processed\n",
      "7000 items processed\n",
      "*** All items processed! ***\n"
     ]
    }
   ],
   "source": [
    "allSequences = []\n",
    "outputColumns = np.zeros(tm.numberOfColumns(), dtype=\"uint32\")\n",
    "columnUsage = np.zeros(tm.numberOfColumns(), dtype=\"uint32\")\n",
    "\n",
    "# Set epochs for spatial-pooling:\n",
    "spEpochs = 5\n",
    "\n",
    "for epoch in range(spEpochs):\n",
    "    print \"Training epoch: \" + str(epoch)\n",
    "    \n",
    "    #randomize records in training set\n",
    "    randomIndex = np.random.permutation(np.arange(numTrainingItems))\n",
    "    \n",
    "    for i in range(numTrainingItems):\n",
    "        sp.compute(trainSet[randomIndex[i]], True, outputColumns)\n",
    "        # Populate array for Yuwei plot:\n",
    "        for col in outputColumns.nonzero():\n",
    "            columnUsage[col] += 1                        \n",
    "        if epoch == (spEpochs - 1):\n",
    "            allSequences.append(outputColumns.nonzero()) \n",
    "\n",
    "for i in range(maxItems - numTrainingItems):\n",
    "    if i > 0 and i % 500 == 0:\n",
    "        print str(i) + \" items processed\"    \n",
    "    sp.compute(nonTrainSet[i], False, outputColumns)\n",
    "    allSequences.append(outputColumns.nonzero())\n",
    "    # Populate array for Yuwei plot:\n",
    "    for col in outputColumns.nonzero():\n",
    "        columnUsage[col] += 1                \n",
    "\n",
    "print \"*** All items processed! ***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bins = 50\n",
    "plt.hist(columnUsage, bins)\n",
    "plt.xlabel(\"Number of times active\")\n",
    "plt.ylabel(\"Number of columns\")\n",
    "plt.savefig(\"columnUsage_SP\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Temporal Memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 items processed\n",
      "500 items processed\n",
      "1000 items processed\n",
      "1500 items processed\n",
      "2000 items processed\n",
      "2500 items processed\n",
      "++ Analyzing correlations (cells at random) ++\n",
      "++ Generating histogram ++\n",
      "++ Computing entropy ++\n",
      "++ Analyzing correlations (whole columns) ++\n",
      "++ Generating histogram ++\n",
      "++ Generating heatmap ++\n",
      "3000 items processed\n",
      "3500 items processed\n",
      "4000 items processed\n",
      "4500 items processed\n",
      "5000 items processed\n",
      "++ Analyzing correlations (cells at random) ++\n",
      "++ Generating histogram ++\n",
      "++ Computing entropy ++\n",
      "++ Analyzing correlations (whole columns) ++\n",
      "++ Generating histogram ++\n",
      "++ Generating heatmap ++\n",
      "5500 items processed\n",
      "6000 items processed\n",
      "6500 items processed\n",
      "7000 items processed\n",
      "7500 items processed\n",
      "++ Analyzing correlations (cells at random) ++\n",
      "++ Generating histogram ++\n",
      "++ Computing entropy ++\n",
      "++ Analyzing correlations (whole columns) ++\n",
      "++ Generating histogram ++\n",
      "++ Generating heatmap ++\n",
      "8000 items processed\n",
      "8500 items processed\n",
      "9000 items processed\n",
      "9500 items processed\n",
      "10000 items processed\n",
      "++ Analyzing correlations (cells at random) ++\n",
      "++ Generating histogram ++\n",
      "++ Computing entropy ++\n",
      "++ Analyzing correlations (whole columns) ++\n",
      "++ Generating histogram ++\n",
      "++ Generating heatmap ++\n",
      "10500 items processed\n",
      "11000 items processed\n",
      "11500 items processed\n",
      "12000 items processed\n",
      "12500 items processed\n",
      "++ Analyzing correlations (cells at random) ++\n",
      "++ Generating histogram ++\n",
      "++ Computing entropy ++\n",
      "++ Analyzing correlations (whole columns) ++\n",
      "++ Generating histogram ++\n",
      "++ Generating heatmap ++\n",
      "13000 items processed\n",
      "13500 items processed\n",
      "14000 items processed\n",
      "14500 items processed\n",
      "***All items processed!***\n"
     ]
    }
   ],
   "source": [
    "spikeTrains = np.zeros((tm.numberOfCells(), totalTS), dtype = \"uint32\")\n",
    "columnUsage = np.zeros(tm.numberOfColumns(), dtype=\"uint32\")\n",
    "ts = 0\n",
    "\n",
    "entropyX = []\n",
    "entropyY = []\n",
    "\n",
    "negPCCX_cells = []\n",
    "negPCCY_cells = []\n",
    "\n",
    "negPCCX_cols = []\n",
    "negPCCY_cols = []\n",
    "\n",
    "# Randomly generate the indices of the columns to keep track during simulation time\n",
    "colIndices = np.random.permutation(tm.numberOfColumns())[0:4] # keep track of 4 columns\n",
    "\n",
    "\n",
    "for s in range(maxItems):\n",
    "    if s % 500 == 0:\n",
    "        print str(s) + \" items processed\"\n",
    "        \n",
    "    tm.compute(allSequences[s][0].tolist(), learn=True)\n",
    "    for cell in tm.getActiveCells():\n",
    "        spikeTrains[cell, ts] = 1            \n",
    "    # Obtain active columns:\n",
    "    activeColumnsIndices = [tm.columnForCell(i) for i in tm.getActiveCells()]\n",
    "    currentColumns = [1 if i in activeColumnsIndices else 0 for i in range(tm.numberOfColumns())]\n",
    "    for col in np.nonzero(currentColumns)[0]:\n",
    "        columnUsage[col] += 1                \n",
    "    \n",
    "    if s > 0 and s % 2500 == 0:\n",
    "        print \"++ Analyzing correlations (cells at random) ++\"                \n",
    "        subSpikeTrains = subSample(spikeTrains, 1000, tm.numberOfCells(), ts)\n",
    "        (corrMatrix, numNegPCC) = computePWCorrelations(subSpikeTrains, removeAutoCorr=True)\n",
    "        negPCCX_cells.append(s)\n",
    "        negPCCY_cells.append(numNegPCC)                \n",
    "        print \"++ Generating histogram ++\"\n",
    "        bins = 300\n",
    "        plt.hist(corrMatrix.ravel(), bins, alpha=0.5)                \n",
    "        # Set range for plot appropriately!\n",
    "        plt.xlim(-0.05,0.1)\n",
    "        plt.xlabel(\"PCC\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.savefig(\"cellsHist\" + str(s))\n",
    "        plt.close()\n",
    "        # Compute entropy\n",
    "        print \"++ Computing entropy ++\"\n",
    "        entropyX.append(s)\n",
    "        entropyY.append(computeEntropy(subSpikeTrains))  \n",
    "        \n",
    "        print \"++ Analyzing correlations (whole columns) ++\"                \n",
    "        subSpikeTrains = subSampleWholeColumn(spikeTrains, colIndices, tm.getCellsPerColumn(), ts)\n",
    "        (corrMatrix, numNegPCC) = computePWCorrelations(subSpikeTrains, removeAutoCorr=True)\n",
    "        negPCCX_cols.append(s)\n",
    "        negPCCY_cols.append(numNegPCC)\n",
    "        print \"++ Generating histogram ++\"\n",
    "        bins = 100\n",
    "        plt.hist(corrMatrix.ravel(), bins, alpha=0.5)\n",
    "        plt.xlabel(\"PCC\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.savefig(\"colsHist_\" + str(s))\n",
    "        plt.close() \n",
    "        print \"++ Generating heatmap ++\"\n",
    "        plt.imshow(corrMatrix, cmap='spectral', interpolation='nearest')\n",
    "        cb = plt.colorbar()\n",
    "        cb.set_label('PCC')\n",
    "        plt.savefig(\"colsHeatMap_\" + str(s))\n",
    "        plt.close() \n",
    "\n",
    "    ts += 1\n",
    "                \n",
    "print \"***All items processed!***\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot trace of negative PCCs\n",
    "plt.plot(negPCCX_cells, negPCCY_cells)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Negative PCC Count\")\n",
    "plt.savefig(\"negPCCTrace_cells\")\n",
    "plt.close()\n",
    "\n",
    "plt.plot(negPCCX_cols, negPCCY_cols)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Negative PCC Count\")\n",
    "plt.savefig(\"negPCCTrace_cols\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print computeEntropy()\n",
    "plt.plot(entropyX, entropyY)\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Entropy\")\n",
    "plt.savefig(\"entropyTM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(columnUsage)\n",
    "plt.xlabel(\"Number of times active\")\n",
    "plt.ylabel(\"Number of columns\")\n",
    "plt.savefig(\"columnUsage_TM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part IV. Analysis of Spike Trains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting from record no.: 2014\n",
      "Accuracy: 0\n",
      "Active cols: [ 258  327  349  375  390  448  503  520  537  544  608  712  751  755  835\n",
      "  847  900  954  970 1081 1088 1134 1154 1159 1164 1281 1290 1330 1356 1533\n",
      " 1552 1578 1625 1628 1681 1688 1765 1835 1952 1966]\n",
      "Predicted cols: [ 117  120  126  209  281  315  327  333  337  349  372  375  382  448  503\n",
      "  516  520  525  542  544  608  620  634  683  700  712  715  726  751  753\n",
      "  755  756  766  776  814  826  847  878  882  900  902  933  954  970  975\n",
      "  977  994  998 1002 1086 1088 1089 1096 1101 1124 1154 1159 1164 1176 1234\n",
      " 1281 1286 1290 1318 1319 1330 1337 1345 1369 1378 1398 1438 1449 1552 1578\n",
      " 1593 1628 1640 1676 1688 1695 1696 1714 1765 1772 1793 1800 1802 1807 1835\n",
      " 1852 1863 1895 1942 1966 1979 1999 2013]\n",
      "\n",
      "Accuracy: 0.0714285714286\n",
      "Active cols: [  11  209  245  288  299  330  333  363  367  378  530  538  608  646  678\n",
      "  687  834  850  866 1040 1084 1096 1157 1233 1243 1251 1258 1345 1374 1385\n",
      " 1412 1438 1548 1615 1663 1695 1961 1996 2002 2015]\n",
      "Predicted cols: [  13   62  101  102  109  113  122  187  195  209  217  288  299  302  304\n",
      "  306  330  333  363  367  378  393  431  488  518  530  538  608  617  622\n",
      "  624  646  678  687  723  730  743  749  779  791  821  834  840  850  866\n",
      "  930  966 1040 1041 1060 1071 1084 1088 1110 1114 1157 1164 1191 1202 1208\n",
      " 1233 1243 1251 1258 1282 1298 1345 1367 1374 1385 1412 1438 1460 1499 1533\n",
      " 1548 1556 1603 1615 1663 1681 1692 1695 1702 1770 1871 1932 1961 1996 2002\n",
      " 2015 2037]\n",
      "\n",
      "Accuracy: 0.0\n",
      "Active cols: [   0  117  175  194  232  249  293  316  344  356  689  711  876  897  939\n",
      "  940  986 1138 1155 1166 1167 1395 1493 1543 1562 1565 1653 1670 1715 1733\n",
      " 1736 1773 1854 1901 1922 1956 1987 2025 2033 2043]\n",
      "Predicted cols: [   0   48   50   55  117  167  194  209  232  249  259  293  316  330  333\n",
      "  356  367  369  375  378  396  397  480  492  520  525  544  601  608  618\n",
      "  644  663  672  689  722  736  805  820  876  884  897  899  923  940  951\n",
      "  974  988  992 1050 1063 1081 1088 1094 1096 1106 1133 1138 1164 1166 1167\n",
      " 1197 1216 1255 1345 1350 1361 1372 1402 1420 1438 1463 1472 1493 1507 1526\n",
      " 1543 1562 1565 1606 1615 1653 1666 1695 1715 1725 1733 1741 1765 1768 1771\n",
      " 1773 1780 1831 1852 1854 1868 1899 1901 1902 1916 1922 1956 1972 1980 1987\n",
      " 2015 2025 2033 2043]\n",
      "\n",
      "Accuracy: 0.045871559633\n",
      "Active cols: [ 112  327  349  375  503  520  525  542  544  712  746  751  766  776  825\n",
      "  847  900  954  970 1002 1093 1124 1330 1356 1369 1378 1398 1494 1552 1640\n",
      " 1765 1785 1793 1800 1835 1863 1952 1966 1999 2047]\n",
      "Predicted cols: [ 209  281  315  327  337  349  375  382  448  503  520  525  542  544  608\n",
      "  620  634  683  712  715  726  746  750  751  755  756  766  776  814  847\n",
      "  933  954  970  975  998 1002 1086 1101 1124 1159 1164 1234 1281 1318 1319\n",
      " 1330 1369 1378 1398 1438 1552 1593 1628 1640 1676 1688 1696 1714 1765 1772\n",
      " 1793 1800 1802 1835 1852 1863 1895 1942 1966 1979 1999]\n",
      "\n",
      "Accuracy: 0.154929577465\n",
      "Active cols: [ 126  157  315  375  392  448  503  596  602  617  649  675  726  735  757\n",
      "  838  900  933  977 1089 1154 1159 1281 1290 1296 1300 1304 1353 1400 1732\n",
      " 1769 1807 1813 1835 1850 1867 1902 1979 1999 2014]\n",
      "Predicted cols: [ 120  157  327  372  375  480  544  596  643  753  902 1159 1304 1318 1319\n",
      " 1628 1811 1979]\n",
      "\n",
      "Accuracy: 0.0\n",
      "Active cols: [  55  139  184  235  338  344  442  447  455  598  655  668  685  688  700\n",
      "  763  781  831  869  919  961  963  972 1039 1083 1162 1239 1265 1417 1418\n",
      " 1468 1505 1591 1642 1712 1759 1791 1852 1860 1951]\n",
      "Predicted cols: [  24   55   58   74  139  183  184  198  200  226  235  320  339  374  382\n",
      "  397  399  412  425  442  447  454  455  459  494  598  599  619  629  647\n",
      "  685  688  700  706  739  781  788  869  881  919  923  945  963  972  987\n",
      "  988  999 1083 1220 1239 1265 1325 1338 1342 1399 1402 1416 1417 1418 1468\n",
      " 1505 1507 1546 1555 1561 1602 1658 1664 1680 1683 1684 1712 1731 1790 1791\n",
      " 1798 1815 1852 1860 1973 1981 1982 2026 2036]\n",
      "\n",
      "Accuracy: 0.404761904762\n",
      "Active cols: [  55   58   74  139  235  339  391  397  412  442  447  455  459  494  700\n",
      "  919  923  945  988 1067 1083 1162 1239 1265 1325 1326 1402 1416 1417 1418\n",
      " 1468 1507 1680 1683 1712 1744 1768 1791 1852 1973]\n",
      "Predicted cols: [  24   36   55   58   74  139  184  198  200  226  235  320  374  382  397\n",
      "  399  412  416  425  442  447  455  459  494  498  511  598  599  619  629\n",
      "  647  685  688  700  706  739  781  881  919  923  945  963  987  988  992\n",
      "  999 1001 1083 1162 1176 1220 1239 1265 1325 1326 1338 1399 1402 1416 1417\n",
      " 1418 1468 1505 1526 1546 1555 1561 1602 1664 1680 1683 1684 1700 1704 1712\n",
      " 1768 1791 1798 1815 1852 1860 1865 1973 1982 2026 2036]\n",
      "\n",
      "Accuracy: 0.0\n",
      "Active cols: [ 126  176  271  315  327  337  349  375  448  503  516  520  525  544  596\n",
      "  683  726  751  766  814  826  847  902  933  970 1124 1281 1318 1319 1330\n",
      " 1578 1628 1688 1696 1765 1813 1835 1895 1979 1999]\n",
      "Predicted cols: [ 117  120  126  157  209  281  315  327  333  337  349  372  375  378  382\n",
      "  448  488  503  516  520  525  530  542  544  596  608  634  646  678  683\n",
      "  700  712  715  726  734  746  750  751  753  755  756  757  766  776  814\n",
      "  826  847  878  900  902  923  933  954  970  975  977  998 1002 1032 1083\n",
      " 1086 1088 1089 1096 1101 1124 1154 1159 1164 1234 1278 1281 1286 1290 1318\n",
      " 1319 1330 1345 1369 1378 1398 1402 1438 1449 1552 1578 1593 1615 1628 1640\n",
      " 1676 1688 1695 1696 1714 1765 1772 1785 1793 1800 1802 1807 1835 1850 1852\n",
      " 1863 1895 1942 1966 1979 1999 2014]\n",
      "\n",
      "Accuracy: 0.0803571428571\n",
      "Active cols: [ 274  311  460  597  643  828  835  847  878  882  970  994 1081 1088 1107\n",
      " 1117 1164 1174 1306 1330 1337 1342 1379 1422 1488 1500 1552 1591 1607 1625\n",
      " 1681 1705 1790 1893 1942 1966 1981 1993 2000 2013]\n",
      "Predicted cols: [  37  121  183  209  275  330  410  425  486  507  510  597  648  828  835\n",
      "  869  970  971  972  999 1081 1096 1117 1123 1164 1174 1268 1280 1306 1316\n",
      " 1330 1337 1345 1366 1422 1471 1524 1546 1561 1607 1681 1686 1705 1790 1866\n",
      " 1893 1910 1942 1953 1974 1993 2000 2026]\n",
      "\n",
      "Accuracy: 0.0\n",
      "Active cols: [  62   97  101  162  288  302  306  333  367  378  393  431  488  608  622\n",
      "  646  678  687  743  779  892  930 1060 1114 1157 1202 1217 1233 1297 1412\n",
      " 1438 1460 1469 1548 1615 1702 1871 1961 2002 2015]\n",
      "Predicted cols: [  13   62  101  102  109  113  122  187  195  209  217  288  302  304  306\n",
      "  330  333  363  367  378  431  488  538  543  545  608  617  622  624  646\n",
      "  678  687  723  730  743  749  779  791  821  834  840  850  866  930  966\n",
      " 1040 1041 1060 1084 1088 1110 1114 1157 1164 1191 1202 1208 1217 1233 1243\n",
      " 1251 1282 1298 1345 1367 1374 1412 1426 1438 1460 1462 1469 1499 1548 1556\n",
      " 1575 1603 1615 1663 1692 1695 1702 1729 1770 1871 1932 1961 1996 2002 2015\n",
      " 2037]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "simpleAccuracyTest(\"periodic\", tm, allSequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subSpikeTrains = subSample(spikeTrains, 1000, tm.numberOfCells(), totalTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250 cells processed\n",
      "500 cells processed\n",
      "750 cells processed\n",
      "**All cells processed**\n"
     ]
    }
   ],
   "source": [
    "isi = computeISI(subSpikeTrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#bins = np.linspace(np.min(isi), np.max(isi), 50)\n",
    "bins = 100\n",
    "plt.hist(isi, bins)\n",
    "# plt.xlim(0,4000)\n",
    "# plt.xlim(89500,92000)\n",
    "plt.xlabel(\"ISI\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"isiTM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part V. Save TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "saveTM(tm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# to load the TM back from the file do:\n",
    "with open('tm.nta', 'rb') as f:\n",
    "    proto2 = TemporalMemoryProto_capnp.TemporalMemoryProto.read(f, traversal_limit_in_words=2**61)\n",
    "tm = TM.read(proto2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part VI. Analysis of Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 rows processed\n",
      "500 rows processed\n",
      "1000 rows processed\n",
      "1500 rows processed\n",
      "2000 rows processed\n",
      "2500 rows processed\n",
      "3000 rows processed\n",
      "3500 rows processed\n",
      "4000 rows processed\n",
      "4500 rows processed\n",
      "5000 rows processed\n",
      "5500 rows processed\n",
      "6000 rows processed\n",
      "6500 rows processed\n",
      "7000 rows processed\n",
      "7500 rows processed\n",
      "8000 rows processed\n",
      "8500 rows processed\n",
      "9000 rows processed\n",
      "9500 rows processed\n",
      "10000 rows processed\n",
      "10500 rows processed\n",
      "11000 rows processed\n",
      "11500 rows processed\n",
      "12000 rows processed\n",
      "12500 rows processed\n",
      "13000 rows processed\n",
      "13500 rows processed\n",
      "14000 rows processed\n",
      "14500 rows processed\n",
      "***All rows processed!***\n"
     ]
    }
   ],
   "source": [
    "overlapMatrix = inputAnalysis(allSequences, \"periodic\", tm.numberOfColumns())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show heatmap of overlap matrix\n",
    "plt.imshow(overlapMatrix, cmap='spectral', interpolation='nearest')\n",
    "cb = plt.colorbar()\n",
    "cb.set_label('Overlap Score')\n",
    "plt.savefig(\"overlapScore_heatmap\")\n",
    "plt.close()\n",
    "# plt.show()\n",
    "\n",
    "# generate histogram\n",
    "bins = 60\n",
    "(n, bins, patches) = plt.hist(overlapMatrix.ravel(), bins, alpha=0.5)\n",
    "\n",
    "plt.xlabel(\"Overlap Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"overlapScore_hist\")\n",
    "\n",
    "plt.xlim(0.5,1)\n",
    "plt.ylim(0,1000000)\n",
    "plt.xlabel(\"Overlap Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"overlapScore_hist_ZOOM\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
